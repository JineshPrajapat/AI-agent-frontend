export const chatWithPaperv={
    "chat_session_id": 2,
    "response": "The MCP Gateway is a layered security architecture designed to protect self-hosted MCP Servers by centralizing security responsibilities [2504.19997v1]. It decouples security from MCP servers, centralizes policy enforcement, and enhances security through defense-in-depth and Zero Trust principles [2504.19997v1]. The core components include a Security Proxy, Authentication Gateway, Zero Trust Tunneling, Security Middleware, and Backend MCP Servers [2504.19997v1]. It enforces strong authentication and authorization through OAuth 2.1 integration and protects communications from interception and lateral movement using secure Zero Trust tunneling [2504.19997v1].\n",
    "sources": {
        "2504.03767v2": {
            "_chunks": [
                {
                    "chunk_id": 3,
                    "score": 0.5861899,
                    "text": "and release patches for exploits using returned remediations. We show that, for the standard MCP servers which enable our demonstrated attacks, McpSafetyScanner is able to correctly identify these vulnerabilities, provide standard exam- ples of these attacks, and remediations . Background 2.1 Need for Standardized Generative AI APIs Currently, the generative AI landscape consists of a wide range of custom APIs tailored towards specific goals and targeted solutions. E.g., for retrieval augmented generation  alone, widely used solutions include Chroma, LangChain, Haystack, LlamaIndex, ChatGPT's retrieval plugin, Huggingface's retrieval plugin, and Azure's Machine Learning pipeline, to name name a few. Furthermore, the aforementioned RAG solutions may internally call several other generative AI APIs, differing based on the inference/LLMOps provider . Such recursive API calls are inherited by practitioners when developing their own specific applications, who in turn build their own custom APIs. Thus, while a large number of generative AI solutions exist, adapting such solutions for a particular use case requires significant developer time and effort due to the current ad-hoc state of generative AI APIs. 1In this context, we are not only referring to the guardrails enabled through safety fine-tuning the LLM, i.e., alignment . Rather, when discussing a closed-source LLM accessed via a server endpoint , we use the term guardrails to encompass all facets of the LLM-inference-endpoint's refusal system, which may include malicious prompt detectors  for either the input query or the LLM's response. Preprint. Under review. 2.2 The Model Context Protocol The MCP is a streamlined solution to the current unstructured design of generative AI APIs. At its core, the MCP defines a schema with which client- and server-side services must structure their requests. Additionally, the MCP consists of an open-source SDK to enable quick adaptation across popular web-development languages ."
                },
                {
                    "chunk_id": 1,
                    "score": 0.5690112,
                    "text": "The described MCP server auditing tool, MCPSafetyScanner, is freely avail- able at: https://github.com/johnhalloran321/mcpSafetyScanner. Introduction With the rise of large language models  and agentic workflows, AI is being developed and adapted at unprecedented rates. Anticipating such growth, as well as the ensuing complexity resulting from AI-powered assistants and services communicating with one another, Anthropic has recently introduced the Model Context Protocol  . This protocol seeks to integrate LLMs and agents with various external systems and services in an easily adaptable framework. Since it's debut, the MCP has been widely adapted across a large number of commonly used open-source libraries, e.g., default MCP servers are natively packaged with Claude Desktop Anthropic , and official integrations include OpenAI's Agents , Copilot , Stripe , Slack , and IBM's Watson , to name a few. Furthermore, the MCP has garnered significant commu- nity interest and support; in just four months , the official MCP github repository has accrued over 27k stars  and has been forked over 2.8k times. Indeed, as the use of AI agents and AI-powered applications continues to grow, it is expected that the MCP will similarly continue to grow as a unifying framework for the \u2217Equal Contribution arXiv:2504.03767v2 [cs.CR] 11 Apr 2025 Preprint. Under review. growing AI-based ecoysytem . However, we show that the current design of the MCP poses significant security risks for users developing generative AI solutions. Herein, we demonstrate that industry-leading LLMs may be coerced to use tools from standard MCP servers and directly compromise user systems. In particular, we show that Claude 3.7 and Llama-3.3-70B may be prompted to use tools from default MCP servers which allow three different types of attacks: 1) malicious code execution,  remote access control, and  credential theft. Furthermore, we introduce a new multi-MCP server attack which enables both remote access control and"
                },
                {
                    "chunk_id": 20,
                    "score": 0.56729364,
                    "text": "servers listed in Table 2 with tools listed in Table 3 Preprint. Under review. Figure 21: McpSafetyScanner second report: Result of McpSafetyScanner scanning the MCP servers listed in Table 2 with tools listed in Table 3. Due to the stochasticity of the agents involved, more scans may catch more vulnerabilities . 27"
                },
                {
                    "chunk_id": 0,
                    "score": 0.557386,
                    "text": "Preprint. Under review. MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits Brandon Radosevich\u2217 John T. Halloran\u2217 Leidos halloranjt@leidos.com Abstract To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol   has recently been released and, subsequently, widely adapted. The MCP is an open proto- col which standardizes API calls to large language models , data sources, and agentic tools. Thus, by connecting multiple MCP servers\u2013each defined with a set of tools, resources, and prompts\u2013users are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries a wide range of security risks for end-users. In particular, we show that industry-leading LLMs may be coerced to use MCP tools and compromise an AI developer's system through a wide range of attacks, e.g., malicious code execution, remote access control, and credential theft. In order to proactively mitigate the demonstrated  attacks, we introduce a safety auditing tool, McpSafetyScanner, the first such agentic tool to assess the security of an arbitrary MCP server. McpSafetyScanner uses several agents to: a) automatically determine ad- versarial samples given an MCP server's tools and resources,  search for related vulnerabilities and remediations given such samples, and  generate a security report detailing all findings. Our work thus sheds light on serious security issues with general purpose agentic workflows, while also providing a proactive tool to audit the safety of MCP servers and address detected vulnerabilities prior to deployment. The described MCP server auditing tool, MCPSafetyScanner, is freely avail- able at: https://github.com/johnhalloran321/mcpSafetyScanner. Introduction With the rise of large language models  and agentic workflows, AI is being developed and adapted at unprecedented rates. Anticipating such"
                },
                {
                    "chunk_id": 9,
                    "score": 0.55375266,
                    "text": "keys file. The attack proceeds as before, where after the user tells Claude to query the database for \"MCP\" and run the results, Claude uses the Chroma MCP server to run the query and the filesystem MCP server to create the authorized keys file with the attacker's ssh keys, thus granting immediate access to the victim's system. McpSafetyScanner - Multi-Agentic Framework for Proactive MCP Vulnerability Detection and Remediation We have thus seen several malicious system attacks made possible by querying Claude or Llama-3.3-70B-Instruct connected to MCP servers. Furthermore, we have seen that, while the LLM's guardrails may be triggered by MCE, RAC, or CT attacks, refusal of the related requests are not guaranteed . Thus, to add security beyond just an LLM's guardrails to MCP-enabled systems, we introduce McpSafetyScanner. Given an arbitrary MCP server, McpSafetyScanner uses agents to automatically probe the system environment and actions enabled by the server for vulnerabilities and subsequent remediations. Depicted in Figure 5, this entire process is carried out in three key stages. The first stage consists of automated vulnerability detection, wherein a hacker agent auto- matically pulls down an MCP server's features , then determines system vulnerabilities using these features. The second stage consists of an expanded vulnerability search and remediation, wherein, for each  tuple, a security auditor agent searches several knowledge bases  for similar vulnerabilities. For each determined vulnerability, the auditor thus determines remediation steps and best practices for an MCP developer to mitigate these exploits. The final stage consists of the security report genera- tion, wherein a supervisor agent consolidates all vulnerabilities and remediations to produce a detailed report. Preprint. Under review.  RADE attack file for CT centered around the theme \"MCP.\"  Claude is successfully coerced to perform a RADE attack using available MCP servers, exporting the"
                }
            ],
            "text": "and release patches for exploits using returned remediations. We show that, for the standard MCP servers which enable our demonstrated attacks, McpSafetyScanner is able to correctly identify these vulnerabilities, provide standard exam- ples of these attacks, and remediations . Background 2.1 Need for Standardized Generative AI APIs Currently, the generative AI landscape consists of a wide range of custom APIs tailored towards specific goals and targeted solutions. E.g., for retrieval augmented generation  alone, widely used solutions include Chroma, LangChain, Haystack, LlamaIndex, ChatGPT's retrieval plugin, Huggingface's retrieval plugin, and Azure's Machine Learning pipeline, to name name a few. Furthermore, the aforementioned RAG solutions may internally call several other generative AI APIs, differing based on the inference/LLMOps provider . Such recursive API calls are inherited by practitioners when developing their own specific applications, who in turn build their own custom APIs. Thus, while a large number of generative AI solutions exist, adapting such solutions for a particular use case requires significant developer time and effort due to the current ad-hoc state of generative AI APIs. 1In this context, we are not only referring to the guardrails enabled through safety fine-tuning the LLM, i.e., alignment . Rather, when discussing a closed-source LLM accessed via a server endpoint , we use the term guardrails to encompass all facets of the LLM-inference-endpoint's refusal system, which may include malicious prompt detectors  for either the input query or the LLM's response. Preprint. Under review. 2.2 The Model Context Protocol The MCP is a streamlined solution to the current unstructured design of generative AI APIs. At its core, the MCP defines a schema with which client- and server-side services must structure their requests. Additionally, the MCP consists of an open-source SDK to enable quick adaptation across popular web-development languages .\n\n---\n\nThe described MCP server auditing tool, MCPSafetyScanner, is freely avail- able at: https://github.com/johnhalloran321/mcpSafetyScanner. Introduction With the rise of large language models  and agentic workflows, AI is being developed and adapted at unprecedented rates. Anticipating such growth, as well as the ensuing complexity resulting from AI-powered assistants and services communicating with one another, Anthropic has recently introduced the Model Context Protocol  . This protocol seeks to integrate LLMs and agents with various external systems and services in an easily adaptable framework. Since it's debut, the MCP has been widely adapted across a large number of commonly used open-source libraries, e.g., default MCP servers are natively packaged with Claude Desktop Anthropic , and official integrations include OpenAI's Agents , Copilot , Stripe , Slack , and IBM's Watson , to name a few. Furthermore, the MCP has garnered significant commu- nity interest and support; in just four months , the official MCP github repository has accrued over 27k stars  and has been forked over 2.8k times. Indeed, as the use of AI agents and AI-powered applications continues to grow, it is expected that the MCP will similarly continue to grow as a unifying framework for the \u2217Equal Contribution arXiv:2504.03767v2 [cs.CR] 11 Apr 2025 Preprint. Under review. growing AI-based ecoysytem . However, we show that the current design of the MCP poses significant security risks for users developing generative AI solutions. Herein, we demonstrate that industry-leading LLMs may be coerced to use tools from standard MCP servers and directly compromise user systems. In particular, we show that Claude 3.7 and Llama-3.3-70B may be prompted to use tools from default MCP servers which allow three different types of attacks: 1) malicious code execution,  remote access control, and  credential theft. Furthermore, we introduce a new multi-MCP server attack which enables both remote access control and\n\n---\n\nservers listed in Table 2 with tools listed in Table 3 Preprint. Under review. Figure 21: McpSafetyScanner second report: Result of McpSafetyScanner scanning the MCP servers listed in Table 2 with tools listed in Table 3. Due to the stochasticity of the agents involved, more scans may catch more vulnerabilities . 27\n\n---\n\nPreprint. Under review. MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits Brandon Radosevich\u2217 John T. Halloran\u2217 Leidos halloranjt@leidos.com Abstract To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol   has recently been released and, subsequently, widely adapted. The MCP is an open proto- col which standardizes API calls to large language models , data sources, and agentic tools. Thus, by connecting multiple MCP servers\u2013each defined with a set of tools, resources, and prompts\u2013users are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries a wide range of security risks for end-users. In particular, we show that industry-leading LLMs may be coerced to use MCP tools and compromise an AI developer's system through a wide range of attacks, e.g., malicious code execution, remote access control, and credential theft. In order to proactively mitigate the demonstrated  attacks, we introduce a safety auditing tool, McpSafetyScanner, the first such agentic tool to assess the security of an arbitrary MCP server. McpSafetyScanner uses several agents to: a) automatically determine ad- versarial samples given an MCP server's tools and resources,  search for related vulnerabilities and remediations given such samples, and  generate a security report detailing all findings. Our work thus sheds light on serious security issues with general purpose agentic workflows, while also providing a proactive tool to audit the safety of MCP servers and address detected vulnerabilities prior to deployment. The described MCP server auditing tool, MCPSafetyScanner, is freely avail- able at: https://github.com/johnhalloran321/mcpSafetyScanner. Introduction With the rise of large language models  and agentic workflows, AI is being developed and adapted at unprecedented rates. Anticipating such\n\n---\n\nkeys file. The attack proceeds as before, where after the user tells Claude to query the database for \"MCP\" and run the results, Claude uses the Chroma MCP server to run the query and the filesystem MCP server to create the authorized keys file with the attacker's ssh keys, thus granting immediate access to the victim's system. McpSafetyScanner - Multi-Agentic Framework for Proactive MCP Vulnerability Detection and Remediation We have thus seen several malicious system attacks made possible by querying Claude or Llama-3.3-70B-Instruct connected to MCP servers. Furthermore, we have seen that, while the LLM's guardrails may be triggered by MCE, RAC, or CT attacks, refusal of the related requests are not guaranteed . Thus, to add security beyond just an LLM's guardrails to MCP-enabled systems, we introduce McpSafetyScanner. Given an arbitrary MCP server, McpSafetyScanner uses agents to automatically probe the system environment and actions enabled by the server for vulnerabilities and subsequent remediations. Depicted in Figure 5, this entire process is carried out in three key stages. The first stage consists of automated vulnerability detection, wherein a hacker agent auto- matically pulls down an MCP server's features , then determines system vulnerabilities using these features. The second stage consists of an expanded vulnerability search and remediation, wherein, for each  tuple, a security auditor agent searches several knowledge bases  for similar vulnerabilities. For each determined vulnerability, the auditor thus determines remediation steps and best practices for an MCP developer to mitigate these exploits. The final stage consists of the security report genera- tion, wherein a supervisor agent consolidates all vulnerabilities and remediations to produce a detailed report. Preprint. Under review.  RADE attack file for CT centered around the theme \"MCP.\"  Claude is successfully coerced to perform a RADE attack using available MCP servers, exporting the",
            "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits"
        },
        "2504.08999v1": {
            "_chunks": [
                {
                    "chunk_id": 6,
                    "score": 0.6293731,
                    "text": "from degrading performance. 3.2 RESTful API and Endpoints MCP Bridge exposes a comprehensive REST API that standardizes access to MCP server functionality. The API is organized into general endpoints for server management and server-specific endpoints for tool execution and resource access. Table 1 summarizes the primary API endpoints provided by MCP Bridge. Table 1 MCP Bridge API Endpoints /health GET Get health status of MCP Bridge /confirmations/{id} POST Confirm execution of a medium-risk request /servers/{id}/tools GET List all tools for a specific server /servers/{id}/tools/{toolName} POST Execute a specific tool /servers/{id}/resources GET List all resources /servers/{id}/prompts GET List all prompts The API design follows REST principles with JSON as the primary data exchange format. Each endpoint returns appropriate HTTP status codes and standardized error responses. For example, when executing a tool via POST /servers/ id /tools/ toolName , the request body contains the tool's input parameters, and the response includes the execution result or a confirmation request based on the tool's risk level. The request processing pipeline  shows how MCP Bridge handles tool execution requests, including validation, risk assessment, and appropriate execution pathways. This unified API layer provides consistent access patterns regardless of the underlying MCP server implementation. 3.3 Server Management and Connection Handling MCP Bridge dynamically manages connections to MCP servers, supporting both stan- dard STDIO-based servers and newer Server-Sent Events  implementations. 5 Endpoint Method Description /servers GET List all connected MCP servers /servers POST Start a new MCP server /servers/{serverId} DELETE Stop and remove a server \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 Algorithm 1 API Request Processing Pipeline 1: Input: HTTP request req with server ID sid, tool name tool, and parameters params 2: Output: HTTP response res with result or confirmation request 3: function"
                },
                {
                    "chunk_id": 2,
                    "score": 0.60132086,
                    "text": "of MCP tool formats poses barriers for non-expert users. In response to these challenges, we present MCP Bridge\u2014a lightweight, fast, and LLM-agnostic proxy that connects to multiple MCP servers and exposes their capa- bilities through a unified REST API. The architecture is shown in Figure 1 Unlike Anthropic's official MCP SDK, MCP Bridge is designed to be fully independent and compatible with any LLM backend, making it adaptable, modular, and future- proof for diverse deployments. Our system implements optional risk-based execution levels to provide granular security controls\u2014from standard execution to confirma- tion workflows and Docker isolation\u2014while maintaining backward compatibility with standard MCP clients. The implementation is available as an open-source project at https://github.com/INQUIRELAB/mcp-bridge-api. The remainder of this paper is organized as follows: Section 2 reviews related work in tool-augmented language models and standardized integration approaches; Section 3 describes the system architecture and implementation of MCP Bridge; Section 4 discusses implications and limitations; and Section 5 concludes with a summary of contributions and directions for future work. 2 Related Work 2.1 Tool Use and Retrieval-Augmented Language Models Large language models  have increasingly been augmented with external data sources and tools to overcome their inherent knowledge and capability limitations 2 Fig. 1 Architecture of the MCP Bridge API system showing four layers: client applications  at the top, connecting through a RESTful API to the MCP Bridge proxy, which interfaces with multiple MCP servers  at the bottom. The system enables resource-constrained environments to access MCP functionality through a unified interface with configurable security levels. [1, 2]. One prominent approach is retrieval-augmented generation , which inte- grates a document retriever with the model. Lewis et al.  introduced RAG as a general framework combining a parametric"
                },
                {
                    "chunk_id": 0,
                    "score": 0.5940457,
                    "text": "MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers Arash Ahmadi1, Sarah Sharif1, Yaser M. Banad1* 1*School of Electrical, and Computer Engineering, University of Oklahoma, Norman, Oklahoma, United States. *Corresponding author. E-mail: bana@ou.edu; Contributing authors: arash.ahmadi-1@ou.edu; s.sh@ou.edu; Abstract Large Language Models  are increasingly augmented with external tools through standardized interfaces like the Model Context Protocol . How- ever, current MCP implementations face critical limitations: they typically require local process execution through STDIO transports, making them imprac- tical for resource-constrained environments like mobile devices, web browsers, and edge computing. We present MCP Bridge, a lightweight RESTful proxy that connects to multiple MCP servers and exposes their capabilities through a unified API. Unlike existing solutions, MCP Bridge is fully LLM-agnostic, supporting any backend regardless of vendor. The system implements a risk-based execution model with three security levels\u2014standard execution, confirmation workflow, and Docker isolation\u2014while maintaining backward compatibility with standard MCP clients. Complementing this server-side infrastructure is a Python-based MCP-Gemini Agent that facilitates natural language interaction with MCP tools. Evaluation demonstrates that MCP Bridge successfully addresses the constraints of direct MCP connections while providing enhanced security controls and cross-platform compatibility, enabling sophisticated LLM-powered applications in previously inaccessible environments. Keywords: Model Context Protocol, Large Language Models, RESTful API, Proxy Architecture, Tool Integration, Risk-Based Execution 1 1 Introduction Large Language Models  have revolutionized natural language processing. They enable sophisticated conversational agents that can understand and generate human-like text across numerous domains . Despite their impressive capabilities,"
                },
                {
                    "chunk_id": 13,
                    "score": 0.59299946,
                    "text": "exploring federated deployment architectures where multiple MCP Bridge instances collaborate to serve geographically distributed clients could improve resilience and reduce latency. Such a distributed approach would require solving com- plex problems of state synchronization and request routing but would yield significant benefits for global-scale AI applications. These enhancements and research directions represent the natural evolution of the MCP Bridge architecture toward an increasingly capable and robust integration layer for LLM-powered tools. 5 Conclusion This paper introduced MCP Bridge, a lightweight, LLM-agnostic proxy that addresses the limitations of direct connections to Model Context Protocol servers. By implement- ing a RESTful API layer between client applications and MCP servers, our solution enables resource-constrained environments such as mobile devices, web browsers, and edge computing platforms to leverage MCP functionality without process execution constraints. The proxy architecture efficiently manages multiple server connections, presenting a unified interface to clients while handling the complexities of different transport mechanisms. A key contribution of MCP Bridge is its risk-based execution model, which pro- vides granular security controls through three distinct levels: standard execution for 11 low-risk operations, confirmation workflows for medium-risk actions, and Docker con- tainer isolation for high-risk processes. This approach balances security requirements with operational flexibility, allowing system administrators to configure appropriate safeguards while maintaining compatibility with standard MCP clients. The comple- mentary MCP-Gemini Agent demonstrates how natural language interfaces can be built atop MCP Bridge, enabling conversational interaction with tools through an intelligent LLM-powered interface. The significance of this work extends beyond its immediate technical implemen- tation. By decoupling client"
                },
                {
                    "chunk_id": 1,
                    "score": 0.5920361,
                    "text": "Tool Integration, Risk-Based Execution 1 1 Introduction Large Language Models  have revolutionized natural language processing. They enable sophisticated conversational agents that can understand and generate human-like text across numerous domains . Despite their impressive capabilities, these models are inherently limited by their training data and lacks access to real-time information, specialized tools, and the ability to perform actions in external systems . To overcome these limitations, there has been a significant push toward augment- ing LLMs with external tools and data sources, allowing them to retrieve information, execute computations, and interact with various services . The Model Context Protocol  represents a significant advancement in this direction, providing a standardized interface for connecting AI assistants to external tools and data sources . Introduced as an open protocol, MCP aims to establish a universal adapter\u2014a \"USB-C port for AI applications\"\u2014that enables any compliant model to access any data repository or service through a consistent format. This standardization addresses the fragmentation problem where each new tool integration requires custom development, replacing it with a single, extensible protocol. However, current MCP implementations face critical limitations that hinder widespread adoption. Many MCP servers rely on STDIO transports that require local process execution, making them impractical for resource-constrained environ- ments such as edge devices, mobile applications, and web browsers. Direct connections to MCP servers from multiple isolated clients also create redundancy and increase resource usage, while the technical complexity of MCP tool formats poses barriers for non-expert users. In response to these challenges, we present MCP Bridge\u2014a lightweight, fast, and LLM-agnostic proxy that connects to multiple MCP servers and exposes their capa- bilities through a unified REST API. The architecture is shown in Figure 1"
                }
            ],
            "text": "from degrading performance. 3.2 RESTful API and Endpoints MCP Bridge exposes a comprehensive REST API that standardizes access to MCP server functionality. The API is organized into general endpoints for server management and server-specific endpoints for tool execution and resource access. Table 1 summarizes the primary API endpoints provided by MCP Bridge. Table 1 MCP Bridge API Endpoints /health GET Get health status of MCP Bridge /confirmations/{id} POST Confirm execution of a medium-risk request /servers/{id}/tools GET List all tools for a specific server /servers/{id}/tools/{toolName} POST Execute a specific tool /servers/{id}/resources GET List all resources /servers/{id}/prompts GET List all prompts The API design follows REST principles with JSON as the primary data exchange format. Each endpoint returns appropriate HTTP status codes and standardized error responses. For example, when executing a tool via POST /servers/ id /tools/ toolName , the request body contains the tool's input parameters, and the response includes the execution result or a confirmation request based on the tool's risk level. The request processing pipeline  shows how MCP Bridge handles tool execution requests, including validation, risk assessment, and appropriate execution pathways. This unified API layer provides consistent access patterns regardless of the underlying MCP server implementation. 3.3 Server Management and Connection Handling MCP Bridge dynamically manages connections to MCP servers, supporting both stan- dard STDIO-based servers and newer Server-Sent Events  implementations. 5 Endpoint Method Description /servers GET List all connected MCP servers /servers POST Start a new MCP server /servers/{serverId} DELETE Stop and remove a server \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 Algorithm 1 API Request Processing Pipeline 1: Input: HTTP request req with server ID sid, tool name tool, and parameters params 2: Output: HTTP response res with result or confirmation request 3: function\n\n---\n\nof MCP tool formats poses barriers for non-expert users. In response to these challenges, we present MCP Bridge\u2014a lightweight, fast, and LLM-agnostic proxy that connects to multiple MCP servers and exposes their capa- bilities through a unified REST API. The architecture is shown in Figure 1 Unlike Anthropic's official MCP SDK, MCP Bridge is designed to be fully independent and compatible with any LLM backend, making it adaptable, modular, and future- proof for diverse deployments. Our system implements optional risk-based execution levels to provide granular security controls\u2014from standard execution to confirma- tion workflows and Docker isolation\u2014while maintaining backward compatibility with standard MCP clients. The implementation is available as an open-source project at https://github.com/INQUIRELAB/mcp-bridge-api. The remainder of this paper is organized as follows: Section 2 reviews related work in tool-augmented language models and standardized integration approaches; Section 3 describes the system architecture and implementation of MCP Bridge; Section 4 discusses implications and limitations; and Section 5 concludes with a summary of contributions and directions for future work. 2 Related Work 2.1 Tool Use and Retrieval-Augmented Language Models Large language models  have increasingly been augmented with external data sources and tools to overcome their inherent knowledge and capability limitations 2 Fig. 1 Architecture of the MCP Bridge API system showing four layers: client applications  at the top, connecting through a RESTful API to the MCP Bridge proxy, which interfaces with multiple MCP servers  at the bottom. The system enables resource-constrained environments to access MCP functionality through a unified interface with configurable security levels. [1, 2]. One prominent approach is retrieval-augmented generation , which inte- grates a document retriever with the model. Lewis et al.  introduced RAG as a general framework combining a parametric\n\n---\n\nMCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers Arash Ahmadi1, Sarah Sharif1, Yaser M. Banad1* 1*School of Electrical, and Computer Engineering, University of Oklahoma, Norman, Oklahoma, United States. *Corresponding author. E-mail: bana@ou.edu; Contributing authors: arash.ahmadi-1@ou.edu; s.sh@ou.edu; Abstract Large Language Models  are increasingly augmented with external tools through standardized interfaces like the Model Context Protocol . How- ever, current MCP implementations face critical limitations: they typically require local process execution through STDIO transports, making them imprac- tical for resource-constrained environments like mobile devices, web browsers, and edge computing. We present MCP Bridge, a lightweight RESTful proxy that connects to multiple MCP servers and exposes their capabilities through a unified API. Unlike existing solutions, MCP Bridge is fully LLM-agnostic, supporting any backend regardless of vendor. The system implements a risk-based execution model with three security levels\u2014standard execution, confirmation workflow, and Docker isolation\u2014while maintaining backward compatibility with standard MCP clients. Complementing this server-side infrastructure is a Python-based MCP-Gemini Agent that facilitates natural language interaction with MCP tools. Evaluation demonstrates that MCP Bridge successfully addresses the constraints of direct MCP connections while providing enhanced security controls and cross-platform compatibility, enabling sophisticated LLM-powered applications in previously inaccessible environments. Keywords: Model Context Protocol, Large Language Models, RESTful API, Proxy Architecture, Tool Integration, Risk-Based Execution 1 1 Introduction Large Language Models  have revolutionized natural language processing. They enable sophisticated conversational agents that can understand and generate human-like text across numerous domains . Despite their impressive capabilities,\n\n---\n\nexploring federated deployment architectures where multiple MCP Bridge instances collaborate to serve geographically distributed clients could improve resilience and reduce latency. Such a distributed approach would require solving com- plex problems of state synchronization and request routing but would yield significant benefits for global-scale AI applications. These enhancements and research directions represent the natural evolution of the MCP Bridge architecture toward an increasingly capable and robust integration layer for LLM-powered tools. 5 Conclusion This paper introduced MCP Bridge, a lightweight, LLM-agnostic proxy that addresses the limitations of direct connections to Model Context Protocol servers. By implement- ing a RESTful API layer between client applications and MCP servers, our solution enables resource-constrained environments such as mobile devices, web browsers, and edge computing platforms to leverage MCP functionality without process execution constraints. The proxy architecture efficiently manages multiple server connections, presenting a unified interface to clients while handling the complexities of different transport mechanisms. A key contribution of MCP Bridge is its risk-based execution model, which pro- vides granular security controls through three distinct levels: standard execution for 11 low-risk operations, confirmation workflows for medium-risk actions, and Docker con- tainer isolation for high-risk processes. This approach balances security requirements with operational flexibility, allowing system administrators to configure appropriate safeguards while maintaining compatibility with standard MCP clients. The comple- mentary MCP-Gemini Agent demonstrates how natural language interfaces can be built atop MCP Bridge, enabling conversational interaction with tools through an intelligent LLM-powered interface. The significance of this work extends beyond its immediate technical implemen- tation. By decoupling client\n\n---\n\nTool Integration, Risk-Based Execution 1 1 Introduction Large Language Models  have revolutionized natural language processing. They enable sophisticated conversational agents that can understand and generate human-like text across numerous domains . Despite their impressive capabilities, these models are inherently limited by their training data and lacks access to real-time information, specialized tools, and the ability to perform actions in external systems . To overcome these limitations, there has been a significant push toward augment- ing LLMs with external tools and data sources, allowing them to retrieve information, execute computations, and interact with various services . The Model Context Protocol  represents a significant advancement in this direction, providing a standardized interface for connecting AI assistants to external tools and data sources . Introduced as an open protocol, MCP aims to establish a universal adapter\u2014a \"USB-C port for AI applications\"\u2014that enables any compliant model to access any data repository or service through a consistent format. This standardization addresses the fragmentation problem where each new tool integration requires custom development, replacing it with a single, extensible protocol. However, current MCP implementations face critical limitations that hinder widespread adoption. Many MCP servers rely on STDIO transports that require local process execution, making them impractical for resource-constrained environ- ments such as edge devices, mobile applications, and web browsers. Direct connections to MCP servers from multiple isolated clients also create redundancy and increase resource usage, while the technical complexity of MCP tool formats poses barriers for non-expert users. In response to these challenges, we present MCP Bridge\u2014a lightweight, fast, and LLM-agnostic proxy that connects to multiple MCP servers and exposes their capa- bilities through a unified REST API. The architecture is shown in Figure 1",
            "title": "MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers"
        },
        "2504.12757v1": {
            "_chunks": [
                {
                    "chunk_id": 3,
                    "score": 0.615205,
                    "text": "scenarios, including a weather-tool MCP server, to illustrate both security efficacy and performance overhead. 4. Empirical and Theoretical Insights: Scenario-based testing of malicious inputs, latency measurements, and throughput analyses, offering an understanding of how MCP Guardian scales and adapts to various domains. 2. Literature Review 2.1 AI Agents and Tool Integration Recent scholarly interest in AI agents has intensified, driven by the desire to move beyond passive text generation and empower Large Language Models  to autonomously perform tasks in real-world contexts. Early attempts at \"tool use\" often relied on bespoke plugins or direct calls to specialized APIs. For instance, OpenAI's ChatGPT introduced plugin frameworks that connect to external services , while other AI-based \"copilot\" tools were designed to read and write files in code repositories. Despite these innovations, the lack of a unified, standardized method for discovering and invoking tools frequently forced developers to create patchwork solutions, thereby increasing the risk of security vulnerabilities, inconsistent access controls, and a limited audit trail. 2.2 The Emergence of MCP The Model Context Protocol \u2014promoted by Anthropic  and further explored by others \u2014addresses these integration challenges by offering an open, extensible protocol for LLM-driven interactions with external tools. By allowing AI clients to query a server for available functions and associated metadata, MCP significantly reduces the repeated overhead encountered in ad-hoc \"plugin\" models. Instead of requiring specialized integrations for each tool, a single request/response channel  serves as a universal interface. This design shares similarities with gRPC or JSON-RPC but is optimized for LLMs' iterative reasoning, where multiple tool calls may be chained in a single session. However, MCP's openness also presents a notable attack surface. Malicious or compromised MCP servers can cloak harmful code under"
                },
                {
                    "chunk_id": 17,
                    "score": 0.61491066,
                    "text": "MCP Guardian cannot fully protect against a compromised server or malicious code within an MCP tool itself. Complementary measures\u2014such as sandboxing and code-signing\u2014are crucial to address deeper supply chain risks. 4. Multi-Agent Context: When multiple LLMs share the same Guardian instance, tracking distinct agent identities and usage quotas becomes non-trivial. Future work might explore identity management solutions that maintain robust per- agent policies and data segregation. 5.5 Interoperability with mcpo Another promising avenue for expanding MCP's usability and security is the mcpo project . This proxy tool exposes any MCP server as a RESTful OpenAPI service, eliminating the need for raw stdio or custom connectors. By automatically generating OpenAPI documentation and leveraging standard HTTP protocols, mcpo makes it easier to integrate existing security controls  and to scale out deployments using conventional web infrastructure. In addition: \u2022 Instant OpenAPI Compatibility: Tools that \"speak OpenAPI\" can seamlessly integrate with MCP-based servers, simplifying the creation of AI-driven applications that rely on mainstream HTTP and JSON. 10 \u2022 Extended Security Features: Because mcpo uses standard web protocols, it can incorporate well-established web security practices  without extensive reconfiguration. \u2022 Improved Discoverability: Automatically generated interactive documentation helps new users or services understand available endpoints, thereby reducing the risk of misconfiguring APIs. By combining MCP Guardian with solutions like mcpo, developers could achieve a layered approach: Guardian handles sophisticated security checks , while mcpo provides a stable, interoperable interface that aligns with modern web standards. Future research may focus on tightly integrating these tools to offer a robust, end-to-end solution for securing, monitoring, and scaling MCP-based AI workflows with minimal developer friction. 6. Conclusion Agentic AI promises to"
                },
                {
                    "chunk_id": 20,
                    "score": 0.60999763,
                    "text": "& Editing, Investigation, Validation, Results. 11 Divyansh Tripathi: Writing, Diagram creation, Review & Editing. References  Anthropic. . Introducing the Model Context Protocol . Retrieved from https://www.anthropic.com/news/model- context-protocol  Cloudflare. . MCP Connectors on Cloudflare Workers. Retrieved from https://blog.cloudflare.com/building-ai-agents- with-mcp-authn-authz-and-durable-objects  OpenAI. . OpenAI Plugins for ChatGPT: Architecture and Security Considerations. Retrieved from https://openai.com/index/chatgpt-plugins  Permit.io. . Fine-Grained Role-Based Access Control for AI Tools. Retrieved from https://www.permit.io/ai-access- control  Invariant Labs. . MCP Security Notification: Tool Poisoning Attacks. Retrieved from https://invariantlabs.ai/blog/mcp- security-notification-tool-poisoning-attacks  Hou, X., Zhao, Y., Wang, S., & Wang, H. . Model Context Protocol : Landscape, Security Threats, and Future Research Directions. Retrieved from https://arxiv.org/html/2503.23278  Equixly. . MCP Servers: The New Security Nightmare. Retrieved from https://equixly.com/blog/2025/03/29/mcp- server-new-security-nightmare/  Gupta, M. . MCP Servers Are Not Safe. Retrieved from https://medium.com/data-science-in-your-pocket/mcp- servers-are-not-safe-bfbc2bb7aef8  Sarig, D. . The Security Risks of Model Context Protocol . Retrieved from https://www.pillar.security/blog/the-security-risks-of-model-context-protocol-mcp  Open WebUI. . mcpo: A Simple, Secure MCP-to-OpenAPI Proxy Server. Retrieved from https://github.com/open- webui/mcpo"
                },
                {
                    "chunk_id": 0,
                    "score": 0.5950835,
                    "text": "1 MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System Sonu Kumar, Anubhav Girdhar, Ritesh Patil and Divyansh Tripathi 1 R&D, Sporo Health, USA. 2 Data Engineering and AI, Involead, India. 3 Gen AI CoE, Capgemini, India. 4 M.Tech in Data Science, IIT Roorkee, India. *Corresponding Author: Sonu Kumar, R&D, Sporo Health, USA. Email: sonu@sporohealth.com Abstract: As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol  addresses this challenge by defining a universal, open standard for securely connecting AI-based applications  to data sources . However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall  scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments. Keywords: model context protocol, mcp, agentic ai, artificial intelligence, generative ai 1. Introduction LLMs have witnessed a rapid expansion in both scale and capability, demonstrating unprecedented performance in tasks ranging from natural language generation to complex programming challenges. While initially confined to relatively passive roles\u2014delivering text-based answers or summaries\u2014LLMs are now increasingly being placed in \"agentic\" positions, where they not only generate content but also initiate"
                },
                {
                    "chunk_id": 9,
                    "score": 0.586313,
                    "text": "Guardian as an intermediate \"middleware\" layer. Rather than requiring developers to embed security checks directly into each tool server, MCP Guardian intercepts all calls via an override of the invoke_tool method in MCP. This design choice ensures minimal disruption to existing 5 codebases while providing a central point of control for authentication, authorization, rate limiting, request monitoring, and Web Application Firewall  scanning. 3.2. Core Components 1. Authentication and Authorization a. Enforces an API-token mechanism, verifying that each request is associated with a valid token. b. Optionally restricts specific tokens to certain tools or to read-only versus administrative privileges. 2. Rate Limiting a. Tracks usage on a per-token basis and denies further requests if a certain threshold is exceeded . b. Prevents resource exhaustion attacks and unintentional \"infinite loop\" scenarios triggered by LLMs. 3. Web Application Firewall  a. Scans request arguments for known malicious patterns . b. Blocks or flags requests exhibiting suspicious behavior, thus preventing unsafe inputs from reaching the underlying MCP server. 4. Logging and Observability a. Logs each request and response, capturing contextual information such as the calling user/agent, request parameters, timestamps, and any triggered warnings. b. Facilitates optional integration with tracing systems like OpenTelemetry, enabling end-to-end correlation of requests across distributed architectures. 3.3. System Architecture Figure 1 Conceptualized below is an illustration of how MCP Guardian fits into a typical LLM-based workflow: Figure 1 MCP Tool Call Sequence 1. Request Interception: The LLM client submits a request specifying which MCP tool it intends to call. 2. Security Checks: MCP Guardian validates the request token, checks rate limits, and scans for malicious patterns. 6 3. Invocation: If the request passes these checks, the Guardian forwards it to the original MCP server. 4. Response"
                }
            ],
            "text": "scenarios, including a weather-tool MCP server, to illustrate both security efficacy and performance overhead. 4. Empirical and Theoretical Insights: Scenario-based testing of malicious inputs, latency measurements, and throughput analyses, offering an understanding of how MCP Guardian scales and adapts to various domains. 2. Literature Review 2.1 AI Agents and Tool Integration Recent scholarly interest in AI agents has intensified, driven by the desire to move beyond passive text generation and empower Large Language Models  to autonomously perform tasks in real-world contexts. Early attempts at \"tool use\" often relied on bespoke plugins or direct calls to specialized APIs. For instance, OpenAI's ChatGPT introduced plugin frameworks that connect to external services , while other AI-based \"copilot\" tools were designed to read and write files in code repositories. Despite these innovations, the lack of a unified, standardized method for discovering and invoking tools frequently forced developers to create patchwork solutions, thereby increasing the risk of security vulnerabilities, inconsistent access controls, and a limited audit trail. 2.2 The Emergence of MCP The Model Context Protocol \u2014promoted by Anthropic  and further explored by others \u2014addresses these integration challenges by offering an open, extensible protocol for LLM-driven interactions with external tools. By allowing AI clients to query a server for available functions and associated metadata, MCP significantly reduces the repeated overhead encountered in ad-hoc \"plugin\" models. Instead of requiring specialized integrations for each tool, a single request/response channel  serves as a universal interface. This design shares similarities with gRPC or JSON-RPC but is optimized for LLMs' iterative reasoning, where multiple tool calls may be chained in a single session. However, MCP's openness also presents a notable attack surface. Malicious or compromised MCP servers can cloak harmful code under\n\n---\n\nMCP Guardian cannot fully protect against a compromised server or malicious code within an MCP tool itself. Complementary measures\u2014such as sandboxing and code-signing\u2014are crucial to address deeper supply chain risks. 4. Multi-Agent Context: When multiple LLMs share the same Guardian instance, tracking distinct agent identities and usage quotas becomes non-trivial. Future work might explore identity management solutions that maintain robust per- agent policies and data segregation. 5.5 Interoperability with mcpo Another promising avenue for expanding MCP's usability and security is the mcpo project . This proxy tool exposes any MCP server as a RESTful OpenAPI service, eliminating the need for raw stdio or custom connectors. By automatically generating OpenAPI documentation and leveraging standard HTTP protocols, mcpo makes it easier to integrate existing security controls  and to scale out deployments using conventional web infrastructure. In addition: \u2022 Instant OpenAPI Compatibility: Tools that \"speak OpenAPI\" can seamlessly integrate with MCP-based servers, simplifying the creation of AI-driven applications that rely on mainstream HTTP and JSON. 10 \u2022 Extended Security Features: Because mcpo uses standard web protocols, it can incorporate well-established web security practices  without extensive reconfiguration. \u2022 Improved Discoverability: Automatically generated interactive documentation helps new users or services understand available endpoints, thereby reducing the risk of misconfiguring APIs. By combining MCP Guardian with solutions like mcpo, developers could achieve a layered approach: Guardian handles sophisticated security checks , while mcpo provides a stable, interoperable interface that aligns with modern web standards. Future research may focus on tightly integrating these tools to offer a robust, end-to-end solution for securing, monitoring, and scaling MCP-based AI workflows with minimal developer friction. 6. Conclusion Agentic AI promises to\n\n---\n\n& Editing, Investigation, Validation, Results. 11 Divyansh Tripathi: Writing, Diagram creation, Review & Editing. References  Anthropic. . Introducing the Model Context Protocol . Retrieved from https://www.anthropic.com/news/model- context-protocol  Cloudflare. . MCP Connectors on Cloudflare Workers. Retrieved from https://blog.cloudflare.com/building-ai-agents- with-mcp-authn-authz-and-durable-objects  OpenAI. . OpenAI Plugins for ChatGPT: Architecture and Security Considerations. Retrieved from https://openai.com/index/chatgpt-plugins  Permit.io. . Fine-Grained Role-Based Access Control for AI Tools. Retrieved from https://www.permit.io/ai-access- control  Invariant Labs. . MCP Security Notification: Tool Poisoning Attacks. Retrieved from https://invariantlabs.ai/blog/mcp- security-notification-tool-poisoning-attacks  Hou, X., Zhao, Y., Wang, S., & Wang, H. . Model Context Protocol : Landscape, Security Threats, and Future Research Directions. Retrieved from https://arxiv.org/html/2503.23278  Equixly. . MCP Servers: The New Security Nightmare. Retrieved from https://equixly.com/blog/2025/03/29/mcp- server-new-security-nightmare/  Gupta, M. . MCP Servers Are Not Safe. Retrieved from https://medium.com/data-science-in-your-pocket/mcp- servers-are-not-safe-bfbc2bb7aef8  Sarig, D. . The Security Risks of Model Context Protocol . Retrieved from https://www.pillar.security/blog/the-security-risks-of-model-context-protocol-mcp  Open WebUI. . mcpo: A Simple, Secure MCP-to-OpenAPI Proxy Server. Retrieved from https://github.com/open- webui/mcpo\n\n---\n\n1 MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System Sonu Kumar, Anubhav Girdhar, Ritesh Patil and Divyansh Tripathi 1 R&D, Sporo Health, USA. 2 Data Engineering and AI, Involead, India. 3 Gen AI CoE, Capgemini, India. 4 M.Tech in Data Science, IIT Roorkee, India. *Corresponding Author: Sonu Kumar, R&D, Sporo Health, USA. Email: sonu@sporohealth.com Abstract: As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol  addresses this challenge by defining a universal, open standard for securely connecting AI-based applications  to data sources . However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall  scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments. Keywords: model context protocol, mcp, agentic ai, artificial intelligence, generative ai 1. Introduction LLMs have witnessed a rapid expansion in both scale and capability, demonstrating unprecedented performance in tasks ranging from natural language generation to complex programming challenges. While initially confined to relatively passive roles\u2014delivering text-based answers or summaries\u2014LLMs are now increasingly being placed in \"agentic\" positions, where they not only generate content but also initiate\n\n---\n\nGuardian as an intermediate \"middleware\" layer. Rather than requiring developers to embed security checks directly into each tool server, MCP Guardian intercepts all calls via an override of the invoke_tool method in MCP. This design choice ensures minimal disruption to existing 5 codebases while providing a central point of control for authentication, authorization, rate limiting, request monitoring, and Web Application Firewall  scanning. 3.2. Core Components 1. Authentication and Authorization a. Enforces an API-token mechanism, verifying that each request is associated with a valid token. b. Optionally restricts specific tokens to certain tools or to read-only versus administrative privileges. 2. Rate Limiting a. Tracks usage on a per-token basis and denies further requests if a certain threshold is exceeded . b. Prevents resource exhaustion attacks and unintentional \"infinite loop\" scenarios triggered by LLMs. 3. Web Application Firewall  a. Scans request arguments for known malicious patterns . b. Blocks or flags requests exhibiting suspicious behavior, thus preventing unsafe inputs from reaching the underlying MCP server. 4. Logging and Observability a. Logs each request and response, capturing contextual information such as the calling user/agent, request parameters, timestamps, and any triggered warnings. b. Facilitates optional integration with tracing systems like OpenTelemetry, enabling end-to-end correlation of requests across distributed architectures. 3.3. System Architecture Figure 1 Conceptualized below is an illustration of how MCP Guardian fits into a typical LLM-based workflow: Figure 1 MCP Tool Call Sequence 1. Request Interception: The LLM client submits a request specifying which MCP tool it intends to call. 2. Security Checks: MCP Guardian validates the request token, checks rate limits, and scans for malicious patterns. 6 3. Invocation: If the request passes these checks, the Guardian forwards it to the original MCP server. 4. Response",
            "title": "MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System"
        },
        "2504.19997v1": {
            "_chunks": [
                {
                    "chunk_id": 1,
                    "score": 0.6662321,
                    "text": "grows, tailored security for protocols like MCP becomes essential. The MCP Gateway mitigates risks without overburdening developers, enabling secure, scalable AI-tool integration. II. CONTRIBUTIONS This paper makes three key contributions:  A reference architecture for MCP Gateways validated through implementation;  Threat model mappings with corresponding mitigation strategies; and  Tool-specific implementation guidelines. III. METHODOLOGY The research methodology comprised:  Analysis of MCP security challenges through technical documentation and community discourse;  Development of security controls compliant with MCP protocol standards; and  Empirical validation via prototype implementation. The approach balanced standardization requirements with practical deployment considerations. IV. ARCHITECTURAL SEPARATION OF MCP COMPONENTS The evolution of MCP's security requirements has led to thoughtful enhancements that better align with enterprise security practices. The 2025-03-26 MCP specification introduced OAuth 2.1 support, prompting a clear distinction between the resource server  and the authorization server . This separation reflects a growing focus on scalability, simplified token management, and alignment with zero-trust architecture\u2014ultimately making the specification more adaptable and robust for enterprise environments. Fig. 1. Separation of Resource and Authorization in MCP Server. This led to the conceptual separation of concerns: the MCP Gateway assumes authorization responsibilities  while MCP servers focus solely on resource provision. The Gateway acts as a policy enforcement point, translating enterprise identity tokens into MCP-specific credentials through a dedicated authentication service. This architecture aligns with enterprise patterns where API gateways front specialized services, while maintaining compliance with MCP specifications through protocol-level interoperability. The separation reduces attack surface  and simplifies server"
                },
                {
                    "chunk_id": 2,
                    "score": 0.65354586,
                    "text": "through a dedicated authentication service. This architecture aligns with enterprise patterns where API gateways front specialized services, while maintaining compliance with MCP specifications through protocol-level interoperability. The separation reduces attack surface  and simplifies server development - critical for adoption in security-conscious environments. V. REFERENCE ARCHITECTURE The MCP Gateway provides a layered security architecture designed to protect self-hosted MCP Servers. Fig. 2. Reference Architecture The MCP gateway's core components include: \u2022 Security Proxy: Handles ingress traffic with TLS termination, rate limiting, and forward authentication delegation. \u2022 Authentication Gateway: Manages OAuth 2.1 flows, integrates with enterprise identity providers, and validates tokens while offloading auth from MCP servers. \u2022 Zero Trust Tunnelling: Establishes identity-aware encrypted tunnels to isolate backend servers, enforcing fine-grained access policies. \u2022 Security Middleware: Performs deep inspection with threat detection and centralized logging. \u2022 Backend MCP Servers: Simplified, isolated components focused solely on tool execution, leveraging the gateway for security. VI. MAPPING TO SECURITY FRAMEWORKS Before proceeding with the detailed threat mapping, it is helpful to briefly review the seven layers of the MAESTRO framework, which structures our analysis. MAESTRO breaks down the AI agent ecosystem into distinct layers: Foundation Models  provide core AI capabilities; Data Operations  and Agent Frameworks  manage data flow and tooling, respectively. Deployment Infrastructure  and Evaluation and Observability  cover the hosting environments and monitoring systems. Security and Compliance  spans across all layers, enforcing governance and control. Finally, the Agent Ecosystem  represents the external interface where business applications interact with users and third-party services. The table below provides a structured and comprehensive mapping"
                },
                {
                    "chunk_id": 4,
                    "score": 0.65315723,
                    "text": "and identified threat categories, based on the security framework proposed by Narajala & Habler . The MCP Gateway addresses the key security requirements outlined by Narajala & Habler by centralizing critical controls across network, application, identity, and monitoring layers. It enforces strong authentication and authorization through OAuth 2.1 integration, mitigating identity and access control subversion. Secure Zero Trust tunnelling protects communications from interception and lateral movement, aligning with their network segmentation principles. Application-level protections such as protocol validation, traffic inspection, and threat detection  defend against resource exhaustion, tool misuse, and injection attacks. The gateway's continuous logging and anomaly detection capabilities support the operational security and continuous monitoring requirements emphasized in the framework. By consolidating these defences at a centralized ingress point, the MCP Gateway simplifies enterprise deployments while meeting the defence-in-depth, Zero Trust, and secure tool management practices advocated for robust MCP security. VII. PROOF OF CONCEPT IMPLEMENTATION To validate the feasibility and security potential of the proposed MCP Gateway architecture, we developed a working proof of concept  using publicly available tools and minimal custom infrastructure. This implementation demonstrates how a modular, zero-trust gateway can securely mediate interactions between MCP clients and servers without embedding complex authorization logic into the backend. The PoC was deployed on a hardened public facing Virtual Private Server  running Ubuntu Linux . This setup provided a reliable and transparent environment for the deployment, ensuring compatibility with the components used in the implementation. Pangolin acted as the central management server, providing identity and access management. It securely exposed the local MCP server via WireGuard tunnels, preventing direct exposure"
                },
                {
                    "chunk_id": 7,
                    "score": 0.65285,
                    "text": "server URI required for the OAuth exchange. Following successful user authentication, the client reattempts the original request, and the gateway proxy authorizes access based on the validated OAuth token, seamlessly enabling secure and authenticated communication with the MCP server. Fig. 4. External OAuth2 message flow This PoC demonstrates that a dedicated MCP Gateway can effectively externalize authentication, authorization, and traffic inspection from the MCP servers, aligning with the updated OAuth 2.1 requirements of the official MCP Specification . It further confirms that modern open-source components can be composed into a secure, flexible architecture suitable for enterprise-scale AI integration. Fig. 5 below shows key snippets of the Traefik configuration demonstrating the implementation of essential security features. These include the setup of middleware for MCP authentication, OAuth metadata redirection, and CrowdSec protection. Fig. 5. Traefik Configuration \u2013 dynamic_config.yaml VIII. EVALUATION AND DISCUSSION Qualitative testing showed the gateway's potential: The Oauth2 Gateway enforced authentication; Traefik blocked unauthenticated requests; invalid Authorization tokens were rejected. Traefik rate limiting and CrowdSec blocked excessive requests. Backend servers were isolated via WireGuard. Centralized authentication and WAF avoided replication on backend servers. Embedding security in each MCP server leads to duplication and complexity so offloading to a specific gateway shows merits. Benefits: The MCP Gateway decouples security from MCP servers, centralizes policy enforcement, enhances security posture through defence-in-depth and Zero Trust, and simplifies compliance with centralized logging. Comparison with Alternatives: Standard API Gateways lack MCP-specific threat understanding and Public MCP gateway solutions do not yet fully address enterprise self-hosted needs. Limitations and Challenges: Challenges and risks include the complexity of"
                },
                {
                    "chunk_id": 8,
                    "score": 0.6459051,
                    "text": "compliance with centralized logging. Comparison with Alternatives: Standard API Gateways lack MCP-specific threat understanding and Public MCP gateway solutions do not yet fully address enterprise self-hosted needs. Limitations and Challenges: Challenges and risks include the complexity of integrating components, performance overhead from security processes, managing keys/tokens, tuning threat detection rules, and ensuring reliable tunnel management. Another important consideration is the maturity of foundational components: Pangolin, which underpins the tunnelling and management framework, is a relatively new open-source project  and depends on several underlying technologies, including WireGuard. Over time, the security resilience of Pangolin and its ecosystem will become clearer through broader adoption, auditing, and community contributions. Further Research: Future work includes advanced AI/ML-based tool behaviour analysis, developing custom parsers, scenarios, and collections to enhance the MCP Gateway's intrusion detection capabilities, enabling more accurate detection of protocol-specific threats and contributing reusable security modules back to the broader open-source community, and more granular, context-aware authorization. IX. CONCLUSION The proposed MCP Gateway architecture enables secure enterprise MCP adoption by centralizing security responsibilities. PoC results show feasibility in mitigating key risks. By abstracting complexity, it facilitates robust, secure, scalable, and spec-compliant AI integrations, crucial for trustworthy AI systems. While challenges remain, the gateway pattern offers a pragmatic path for managing MCP security at scale. X. REFERENCES  Anthropic, \"Introducing the model context protocol,\" Anthropic Developers Documentation, 2024. Accessed: 2025-04-01. [Online]. Available: https://developers.anthropic.com/  Opensource Community, \"Specification - Model Context Protocol,\" March 2025. [Online]. Available:"
                }
            ],
            "text": "grows, tailored security for protocols like MCP becomes essential. The MCP Gateway mitigates risks without overburdening developers, enabling secure, scalable AI-tool integration. II. CONTRIBUTIONS This paper makes three key contributions:  A reference architecture for MCP Gateways validated through implementation;  Threat model mappings with corresponding mitigation strategies; and  Tool-specific implementation guidelines. III. METHODOLOGY The research methodology comprised:  Analysis of MCP security challenges through technical documentation and community discourse;  Development of security controls compliant with MCP protocol standards; and  Empirical validation via prototype implementation. The approach balanced standardization requirements with practical deployment considerations. IV. ARCHITECTURAL SEPARATION OF MCP COMPONENTS The evolution of MCP's security requirements has led to thoughtful enhancements that better align with enterprise security practices. The 2025-03-26 MCP specification introduced OAuth 2.1 support, prompting a clear distinction between the resource server  and the authorization server . This separation reflects a growing focus on scalability, simplified token management, and alignment with zero-trust architecture\u2014ultimately making the specification more adaptable and robust for enterprise environments. Fig. 1. Separation of Resource and Authorization in MCP Server. This led to the conceptual separation of concerns: the MCP Gateway assumes authorization responsibilities  while MCP servers focus solely on resource provision. The Gateway acts as a policy enforcement point, translating enterprise identity tokens into MCP-specific credentials through a dedicated authentication service. This architecture aligns with enterprise patterns where API gateways front specialized services, while maintaining compliance with MCP specifications through protocol-level interoperability. The separation reduces attack surface  and simplifies server\n\n---\n\nthrough a dedicated authentication service. This architecture aligns with enterprise patterns where API gateways front specialized services, while maintaining compliance with MCP specifications through protocol-level interoperability. The separation reduces attack surface  and simplifies server development - critical for adoption in security-conscious environments. V. REFERENCE ARCHITECTURE The MCP Gateway provides a layered security architecture designed to protect self-hosted MCP Servers. Fig. 2. Reference Architecture The MCP gateway's core components include: \u2022 Security Proxy: Handles ingress traffic with TLS termination, rate limiting, and forward authentication delegation. \u2022 Authentication Gateway: Manages OAuth 2.1 flows, integrates with enterprise identity providers, and validates tokens while offloading auth from MCP servers. \u2022 Zero Trust Tunnelling: Establishes identity-aware encrypted tunnels to isolate backend servers, enforcing fine-grained access policies. \u2022 Security Middleware: Performs deep inspection with threat detection and centralized logging. \u2022 Backend MCP Servers: Simplified, isolated components focused solely on tool execution, leveraging the gateway for security. VI. MAPPING TO SECURITY FRAMEWORKS Before proceeding with the detailed threat mapping, it is helpful to briefly review the seven layers of the MAESTRO framework, which structures our analysis. MAESTRO breaks down the AI agent ecosystem into distinct layers: Foundation Models  provide core AI capabilities; Data Operations  and Agent Frameworks  manage data flow and tooling, respectively. Deployment Infrastructure  and Evaluation and Observability  cover the hosting environments and monitoring systems. Security and Compliance  spans across all layers, enforcing governance and control. Finally, the Agent Ecosystem  represents the external interface where business applications interact with users and third-party services. The table below provides a structured and comprehensive mapping\n\n---\n\nand identified threat categories, based on the security framework proposed by Narajala & Habler . The MCP Gateway addresses the key security requirements outlined by Narajala & Habler by centralizing critical controls across network, application, identity, and monitoring layers. It enforces strong authentication and authorization through OAuth 2.1 integration, mitigating identity and access control subversion. Secure Zero Trust tunnelling protects communications from interception and lateral movement, aligning with their network segmentation principles. Application-level protections such as protocol validation, traffic inspection, and threat detection  defend against resource exhaustion, tool misuse, and injection attacks. The gateway's continuous logging and anomaly detection capabilities support the operational security and continuous monitoring requirements emphasized in the framework. By consolidating these defences at a centralized ingress point, the MCP Gateway simplifies enterprise deployments while meeting the defence-in-depth, Zero Trust, and secure tool management practices advocated for robust MCP security. VII. PROOF OF CONCEPT IMPLEMENTATION To validate the feasibility and security potential of the proposed MCP Gateway architecture, we developed a working proof of concept  using publicly available tools and minimal custom infrastructure. This implementation demonstrates how a modular, zero-trust gateway can securely mediate interactions between MCP clients and servers without embedding complex authorization logic into the backend. The PoC was deployed on a hardened public facing Virtual Private Server  running Ubuntu Linux . This setup provided a reliable and transparent environment for the deployment, ensuring compatibility with the components used in the implementation. Pangolin acted as the central management server, providing identity and access management. It securely exposed the local MCP server via WireGuard tunnels, preventing direct exposure\n\n---\n\nserver URI required for the OAuth exchange. Following successful user authentication, the client reattempts the original request, and the gateway proxy authorizes access based on the validated OAuth token, seamlessly enabling secure and authenticated communication with the MCP server. Fig. 4. External OAuth2 message flow This PoC demonstrates that a dedicated MCP Gateway can effectively externalize authentication, authorization, and traffic inspection from the MCP servers, aligning with the updated OAuth 2.1 requirements of the official MCP Specification . It further confirms that modern open-source components can be composed into a secure, flexible architecture suitable for enterprise-scale AI integration. Fig. 5 below shows key snippets of the Traefik configuration demonstrating the implementation of essential security features. These include the setup of middleware for MCP authentication, OAuth metadata redirection, and CrowdSec protection. Fig. 5. Traefik Configuration \u2013 dynamic_config.yaml VIII. EVALUATION AND DISCUSSION Qualitative testing showed the gateway's potential: The Oauth2 Gateway enforced authentication; Traefik blocked unauthenticated requests; invalid Authorization tokens were rejected. Traefik rate limiting and CrowdSec blocked excessive requests. Backend servers were isolated via WireGuard. Centralized authentication and WAF avoided replication on backend servers. Embedding security in each MCP server leads to duplication and complexity so offloading to a specific gateway shows merits. Benefits: The MCP Gateway decouples security from MCP servers, centralizes policy enforcement, enhances security posture through defence-in-depth and Zero Trust, and simplifies compliance with centralized logging. Comparison with Alternatives: Standard API Gateways lack MCP-specific threat understanding and Public MCP gateway solutions do not yet fully address enterprise self-hosted needs. Limitations and Challenges: Challenges and risks include the complexity of\n\n---\n\ncompliance with centralized logging. Comparison with Alternatives: Standard API Gateways lack MCP-specific threat understanding and Public MCP gateway solutions do not yet fully address enterprise self-hosted needs. Limitations and Challenges: Challenges and risks include the complexity of integrating components, performance overhead from security processes, managing keys/tokens, tuning threat detection rules, and ensuring reliable tunnel management. Another important consideration is the maturity of foundational components: Pangolin, which underpins the tunnelling and management framework, is a relatively new open-source project  and depends on several underlying technologies, including WireGuard. Over time, the security resilience of Pangolin and its ecosystem will become clearer through broader adoption, auditing, and community contributions. Further Research: Future work includes advanced AI/ML-based tool behaviour analysis, developing custom parsers, scenarios, and collections to enhance the MCP Gateway's intrusion detection capabilities, enabling more accurate detection of protocol-specific threats and contributing reusable security modules back to the broader open-source community, and more granular, context-aware authorization. IX. CONCLUSION The proposed MCP Gateway architecture enables secure enterprise MCP adoption by centralizing security responsibilities. PoC results show feasibility in mitigating key risks. By abstracting complexity, it facilitates robust, secure, scalable, and spec-compliant AI integrations, crucial for trustworthy AI systems. While challenges remain, the gateway pattern offers a pragmatic path for managing MCP security at scale. X. REFERENCES  Anthropic, \"Introducing the model context protocol,\" Anthropic Developers Documentation, 2024. Accessed: 2025-04-01. [Online]. Available: https://developers.anthropic.com/  Opensource Community, \"Specification - Model Context Protocol,\" March 2025. [Online]. Available:",
            "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration"
        }
    },
    "token_usage": {
        "input_tokens": 7403,
        "output_tokens": 156,
        "total_tokens": 7559
    }
}